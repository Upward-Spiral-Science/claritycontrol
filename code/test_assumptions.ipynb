{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavily borrowed text materials and formatting from grelliam\n",
    "\n",
    "##  Testing Assumptions\n",
    "1. State assumptions\n",
    "2. Check assumptions (with figures)\n",
    "    1. residuals\n",
    "    2. correlations\n",
    "    3. \\# of modes\n",
    " \n",
    "### Step 1: State assumptions\n",
    "\n",
    "1. We assume that graphs are sampled according to: $x_i \\stackrel{iid}{\\sim} F$. This is both an independent and identical assumption.\n",
    "\n",
    "\n",
    "### Step 2: Check assumptions\n",
    "\n",
    "For independent graphs, check that off diagonal covariance is approximately 0. <br/>\n",
    "$x_i \\stackrel{iid}{\\sim} F$<br/>\n",
    "$(x_1, x_2, ..., x_n) \\sim F = \\prod_i^n F_i$ <br/>\n",
    "$F_i = F_j, \\forall i,j$\n",
    "\n",
    "For identical graphs, check the optimal number of clusters and see if that is 1. <br/>\n",
    "$F = \\prod_j^J F_j, J < n$ <br/>\n",
    "$\\prod_j^J w_jF_j(\\theta)$ <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change working dir\n",
    "path = \"/Users/albertlee/claritycontrol/code/scripts\" # use your own path\n",
    "import os\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named igraph",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3cf44b220244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0migraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named igraph"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import igraph as ig\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Initializing dataset names\n",
    "dnames = list(['../data/hist'])\n",
    "print \"Dataset: \" + \", \".join(dnames)\n",
    "\n",
    "# Getting graph names\n",
    "fs = list()\n",
    "for dd in dnames:\n",
    "        fs.extend([root+'/'+file for root, dir, files in os.walk(dd) for file in files])\n",
    "fs = fs[1:]\n",
    "def loadGraphs(filenames, rois, printer=False):\n",
    "    A = np.zeros((rois, rois, len(filenames)))\n",
    "    for idx, files in enumerate(filenames):\n",
    "        if printer:\n",
    "            print \"Loading: \" + files\n",
    "        g = ig.Graph.Read_GraphML(files)\n",
    "        tempg = g.get_adjacency(attribute='weight')\n",
    "        A[:,:,idx] = np.asarray(tempg.data)\n",
    "        \n",
    "    return A\n",
    "\n",
    "# Load X\n",
    "X = loadGraphs(fs, 70)\n",
    "print X.shape\n",
    "\n",
    "# Load Y\n",
    "ys = csv.reader(open('../data/points/Fear199.csv'))\n",
    "y = [y[5] for y in ys]\n",
    "y = [1 if x=='F' else 0 for x in y[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent Graph Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorized = np.reshape(X, (X.shape[0]**2, X.shape[2])).T\n",
    "covar = np.cov(vectorized)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(covar)\n",
    "plt.title('Covariance of KKI2009 dataset')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "diag = covar.diagonal()*np.eye(covar.shape[0])\n",
    "hollow = covar-diag\n",
    "d_det = np.linalg.det(diag)\n",
    "h_det = np.linalg.det(hollow)\n",
    "\n",
    "plt.figure(figsize=(11,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(diag)\n",
    "plt.clim([0, np.max(covar)])\n",
    "plt.title('Determinant of on-diagonal: ' + str(d_det))\n",
    "plt.subplot(122)\n",
    "plt.imshow(hollow)\n",
    "plt.clim([0, np.max(covar)])\n",
    "plt.title('Determinant of off-diagonal: ' + str(h_det))\n",
    "plt.show()\n",
    "\n",
    "print \"Ratio of on- and off-diagonal determinants: \" + str(d_det/h_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we conclude that the assumption that the graphs were independent is false. This is because the off-diagonal components of the covariance are highly significant in the cross-graph covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identical Graph Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "i = np.linspace(1,15,15,dtype='int')\n",
    "print i\n",
    "bic = np.array(())\n",
    "for idx in i:\n",
    "    print \"Fitting and evaluating model with \" + str(idx) + \" clusters.\"\n",
    "    gmm = sklearn.mixture.GMM(n_components=idx,n_iter=1000,covariance_type='diag')\n",
    "    gmm.fit(vectorized)\n",
    "    bic = np.append(bic, gmm.bic(vectorized))\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(i, 1.0/bic)\n",
    "plt.title('BIC')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.show()\n",
    "print bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we observe that, since the elbow of the bic curve lies at 6, that our data may not have been sampled identically from one distribution. This assumption based on the evidence provided is also false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent Edge Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = np.reshape(X, (X.shape[0]**2, X.shape[2]))\n",
    "covar = np.cov(vect)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(covar)\n",
    "plt.title('Covariance of KKI2009 dataset')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "diag = covar.diagonal()*np.eye(covar.shape[0])\n",
    "hollow = covar-diag\n",
    "d_det = np.sum(diag)\n",
    "h_det = np.sum(hollow)\n",
    "\n",
    "plt.figure(figsize=(11,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(diag)\n",
    "plt.clim([0, np.max(covar)])\n",
    "plt.title('Sum of on-diagonal: ' + str(d_det))\n",
    "plt.subplot(122)\n",
    "plt.imshow(hollow)\n",
    "plt.clim([0, np.max(covar)])\n",
    "plt.title('Sum of off-diagonal: ' + str(h_det))\n",
    "plt.show()\n",
    "\n",
    "print \"Ratio of on- and off-diagonal covariance sums: \" + str(d_det/h_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can conclude that the edges are not independent of one another, as the ratio of on- to off-diagonal covariance is very small. This assumption is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identical Edge Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "i = np.linspace(1,15,15,dtype='int')\n",
    "print i\n",
    "bic2 = np.array(())\n",
    "for idx in i:\n",
    "    print \"Fitting and evaluating model with \" + str(idx) + \" clusters.\"\n",
    "    gmm = sklearn.mixture.GMM(n_components=idx,n_iter=1000,covariance_type='diag')\n",
    "    gmm.fit(vect.T)\n",
    "    bic2 = np.append(bic2, gmm.bic(vect.T))\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(i, 1.0 / bic2)\n",
    "plt.title('BIC')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.show()\n",
    "print bic2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the bic curve, we observe that the optimal number of clusters is 5, indicating that edges are not in fact identically distributed. This assumptions appears to be false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Conditional Edge Probability Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "ya = np.array(y)\n",
    "\n",
    "# clf = sklm.LinearRegression()\n",
    "# print vectorized.T.shape\n",
    "edgeprob = 1.0*np.sum(1.0*(vectorized.T>0),1)/4900\n",
    "# print edgeprob\n",
    "# print ya.shape\n",
    "# vals = clf.fit(edgeprob.T, ya)\n",
    "# slope = clf.coef_\n",
    "# intercept = clf.intercept_\n",
    "\n",
    "vals = ss.linregress(edgeprob, ya)\n",
    "m = vals[0]\n",
    "c = vals[1]\n",
    "\n",
    "\n",
    "\n",
    "def comp_value(m, c, data):\n",
    "    return m.T*data + c\n",
    "\n",
    "resi = np.array(())\n",
    "for idx, subj in enumerate(ya):\n",
    "    temp = comp_value(m, c, edgeprob[idx])\n",
    "    resi = np.append(resi, subj - temp)\n",
    "    \n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(edgeprob, resi)\n",
    "plt.title('Residual assignment error')\n",
    "plt.xlabel('edge probability')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see quite plainly that our classifier fails to separate subjects based on their edge probability. Thus, this assumption is also false."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
